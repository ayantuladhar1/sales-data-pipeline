# Sales Data Pipeline using Medallion Architecture

## ğŸ“Œ Project Overview
This project demonstrates a mini end-to-end Data Engineering pipeline using the Medallion Architecture (Bronze â†’ Silver â†’ Gold).
The pipeline ingests raw sales data, cleans and transforms it using PySpark, and produces analytics-ready datasets stored in Parquet format and queried via Hive.

---

## ğŸ— Architecture
Bronze â†’ Silver â†’ Gold

---

## ğŸ›  Tech Stack
- Python
- PySpark
- Apache Hive
- HDFS
- Parquet
- SQL

---

## ğŸ“‚ Project Structure
**sales-data-pipeline/**
â”œâ”€â”€ data/raw/sales.csv
â”œâ”€â”€ src/
â”‚ â”œâ”€â”€ ingest_bronze.py
â”‚ â”œâ”€â”€ transform_silver.py
â”‚ â”œâ”€â”€ load_gold.py
â”‚ â””â”€â”€ constants.py
â”œâ”€â”€ hive/create_tables.sql
â””â”€â”€ README.md


---

## ğŸ“„ Dataset
| Column | Description |
|------|------------|
| sale_id | Unique sale id |
| product_name | Product name |
| quantity | Units sold |
| price | Price per unit |
| sale_date | Date of sale |

---

## ğŸ”„ Data Flow

### ğŸŸ¤ Bronze Layer
- Raw CSV ingestion
- No transformations
- Stored as Parquet

### âšª Silver Layer
- Cleaned and typed data
- Ready for analytics

### ğŸŸ¡ Gold Layer
- Aggregated sales metrics

---

## ğŸ How to Run

### Step â€“ Bronze/Silver/Gold
```bash
spark-submit src/ingest_bronze.py
spark-submit src/transform_silver.py
spark-submit src/load_gold.py
